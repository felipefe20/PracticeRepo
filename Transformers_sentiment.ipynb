{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felipefe20/Projects/blob/main/Transformers_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DC3FmcLs9Gn",
        "outputId": "1cd87c00-c4d4-4c42-9083-a903e1bddee0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'transformers'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15976/1028372492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Example of classification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFAutoModelForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
          ]
        }
      ],
      "source": [
        "#Example of classification\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "\n",
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        " \n",
        " \n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "# Tasks:\n",
        "# emoji, emotion, hate, irony, offensive, sentiment\n",
        "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
        "\n",
        "task='sentiment'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# download label mapping\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# PT\n",
        "#model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "#model.save_pretrained(MODEL)\n",
        "\n",
        "#text = \"Good night ðŸ˜Š\"\n",
        "#text = preprocess(text)\n",
        "#encoded_input = tokenizer(text, return_tensors='pt')\n",
        "#output = model(**encoded_input)\n",
        "#scores = output[0][0].detach().numpy()\n",
        "#scores = softmax(scores)\n",
        "\n",
        "# # TF\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "tokenizer.save_pretrained(MODEL)\n",
        "text = \"Good night ðŸ˜Š\"\n",
        "encoded_input = tokenizer(text, return_tensors='tf')\n",
        "output = model(encoded_input)\n",
        "scores = output[0][0].numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEUH6YWWuqP7"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQreMXL4vRXT",
        "outputId": "bba57b29-483c-4203-a423-85605d354792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1) neutral 0.5717\n",
            "2) positive 0.3135\n",
            "3) negative 0.1147\n"
          ]
        }
      ],
      "source": [
        "text = \"Call with @SecBlinken on further steps to strengthen Ukraineâ€™s defense capabilities. Grateful to the U.S. for the new package of tough sanctions on Russia. Pressure must be elevating until Russia stops its brutal aggression and barbaric war crimes against Ukrainians.\"\n",
        "encoded_input = tokenizer(text, return_tensors='tf')\n",
        "output = model(encoded_input)\n",
        "scores = output[0][0].numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0UOvUgVvWK5",
        "outputId": "2889bb43-7fee-4150-cd74-5b87d695121a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'summary_text': 'China abstained on a United Nations resolution condemning Russia\\'s invasion. But its government has expressed \"regret\" about the military action. News of the resignations comes as the US warned'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "ARTICLE=\"\"\"News of the resignations comes as the US warned Chinese companies not to breach restrictions on technology exports to Russia.\n",
        "\n",
        "China abstained on a United Nations resolution condemning Russia's invasion but its government has also recently expressed \"regret\" about the military action, saying it was extremely concerned about the harm to civilians.\n",
        "\n",
        "Commerce Secretary Gina Raimondo told the New York Times Washington could take \"devastating\" action against Chinese companies that defied Russian sanctions, prohibiting the use of US equipment and software needed to make their products.\n",
        "\n",
        "Russia \"is certainly going to be courting other countries to do an end run around our sanctions and export controls\", Ms Raimondo told the newspaper.\n",
        "\n",
        "The threats echo measures taken against Huawei in 2020, when Donald Trump's administration added the company to its \"entity list\", which bans it from acquiring technology from US companies without government approval.\n",
        "\n",
        "The US government said at the time it believed Huawei posed a national security threat, something the company strongly denied.\n",
        "\n",
        "But the restrictions hit the company's earnings hard and deprived it of access to key technologies.\"\"\"\n",
        "\n",
        "print(summarizer(ARTICLE, max_length=40, min_length=10, do_sample=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ut4ZA52yzA9"
      },
      "outputs": [],
      "source": [
        "\"testing new things, this is the way\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP05tpw0qTF4n8AA+KwItZL",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Transformers_sentiment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
